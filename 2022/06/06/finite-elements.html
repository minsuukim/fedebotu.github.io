<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Finite Element Networks | Minsu Kim</title> <meta name="author" content="Minsu Kim"/> <meta name="description" content="A review on the paper "Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks" (ICLR 2022)"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/diffeqml.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://minsuukim.github.io/2022/06/06/finite-elements.html"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Minsu </span>Kim</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/collaborators/">collaborators</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/workshop%20presentations/">workshop presentations</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Finite Element Networks</h1> <p class="post-meta">June 6, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a> </p> </header> <article class="post-content"> <h1 id="learning-the-dynamics-of-physical-systems-from-sparse-observations-with-finite-element-networks">Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks</h1> <p>We will present a blog post on <a href="https://arxiv.org/abs/2203.08852" target="_blank" rel="noopener noreferrer"><em>“Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks”</em></a> from Marten Lienen and Stephan Günnemann [1], which has been accepted as a Spotlight presentation in <a href="https://iclr.cc/" target="_blank" rel="noopener noreferrer">ICLR 2022</a>. This was originally a course review for <a href="https://dsail.gitbook.io/isyse-review/paper-review/2022-spring-paper-review" target="_blank" rel="noopener noreferrer">KSE 527</a> at KAIST.</p> <h2 id="1-problem-definition"><strong>1. Problem Definition</strong></h2> <p>We will firstly introduce the problem in a brief, yet somewhat lengthy, necessary background about differential equations and the finite element method that constitutes a backbone of the paper.</p> <h3 id="modeling-complex-systems-with-differential-equations">Modeling Complex Systems with Differential Equations</h3> <p>Differential Equations are regarded by many as the <em>language of nature</em>. Many complex systems can be modeled by describing each single variable as a relation with others in both <em>space</em> and <em>time</em>: Partial Differential Equations (PDEs) describe such processes. A quite general formulation can be written as following:</p> \[\partial_t u = F (t, x, u, \partial_x u, \partial_{x^2} u, \dots)\] <p>where \(u\) is a solution of the equation and \(F\) are the <em>dynamics</em> which can be a function of time, space, \(u\) itself and its derivatives. PDEs are generally either very expensive to compute if not intractable altogether. For these reason, multiple algorithms have been developed over the centuries to try and solve this extremely complex endeavor. In particular, computers are very capable of handling <em>discretized</em> data, in the form of digital bits instead of their continuous, analog counterparts. Can we apply some algorithm which is well suitable to computers?</p> <h3 id="the-finite-element-method">The Finite Element Method</h3> <p>The Finite Element Method (FEM) is a way to <em>divide and conquer</em> the realm of PDEs.</p> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/fem-example-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/fem-example-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/fem-example-1400.webp"></source> <img src="/assets/img/blogs/fen/fem-example.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1.<i> An example of Finite Element Method (FEM) applied to a magnetical shield. </i> </div> </div> <p>In particular, the domain with set of points \(\mathcal{X}\) is divided into a set of simplices (i.e., \(n\) -dimensional triangles) which is called <em>triangulation</em>. Triangulations, such as the Delaunay triangulation, are also referred to as <em>meshes</em> and are frequently used in many other areas such as movie CGI, gaming and most 3D graphics. This can be seen on the left of Figure 1. Then, operations are performed on this discretized domain to obtain a solution, as shown on the right of Figure 1.</p> <h4 id="basis-functions">Basis Functions</h4> <p>In general, the solution \(u\) would lie in an infinite-dimensional space \(\mathcal{U}\). What if, however, we cannot have infinite dimensions? Then, we need to approximate \(u\) with a finite-dimensional subspace \(\mathcal{\tilde{U}}\). To do so we employ <em>basis functions</em> \(\varphi\), which map points from \(\mathcal{U}\) to \(\mathcal{\tilde{U}}\). The simplest choice, which the authors use, is the P1 piecewise linear functions which map</p> \[\varphi^{(j)} (x^{(i)}) = \begin{cases} 1 &amp; \text{if }x^{(i)} = x^{(j)}\\ 0 &amp; \text{otherwise} \end{cases} \quad \forall x^{(i)} \in \mathcal{X}.\] <p>that is basically to simply map each point in \(\mathcal{U}\) to the same values in \(\mathcal{\tilde{U}}\) as in Figure 2 left.</p> <p>Moreover, another property of expanding \(u \in \mathcal{\tilde{U}}\) is that the following holds:</p> \[u(x^{(i)}) = \sum_{j=1}^N c_j \varphi^{(j)}(x^{(i)}) = c_i\] <p>i.e., the value of \(u\) at the \(i\)-th node is just its \(i\)-th coefficient.</p> <h4 id="galerkin-method">Galerkin Method</h4> <p>The piecewise linear approximation above is not differentiable everywhere. However, we can constrain the residual \(R\), i.e. the difference between \(\partial_t u\) and \(F\) to be orthogonal to the approximation space:</p> \[\langle R(u), \varphi^{(i)} \rangle_\Omega = 0 \quad \forall i \in 1, \dots, N\] <p>where \(\Omega\) represents the spatial domain. In simpler terms, we are asking for the <em>best possible</em> approximation of the equations. Given this, we can now reconstruct the equation as following</p> \[\langle \partial_t u, \varphi^{(i)}\rangle_\Omega = \langle F (t, x, u, \partial_x u, \partial_{x^2} u, \dots), \varphi^{(i)}\rangle_\Omega, \quad \forall i \in 1, \dots, N\] <p>By stacking the equations above we obtain the following linear system \(A \partial_t c = m\)</p> <p>where \(A\) with \(A_{ij} = \langle \varphi^{(i)}, \varphi^{(j)} \rangle_\Omega\) is the so-called mass matrix, \(c\) is the vector of basis coefficients of \(u\) and \(m\) with \(m_i = \langle F(t, x, u, \dots), \varphi^{(i)} \rangle_\Omega\) captures the effects of dynamics \(F\).</p> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/basis-function-choice-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/basis-function-choice-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/basis-function-choice-1400.webp"></source> <img src="/assets/img/blogs/fen/basis-function-choice.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2.<i> Solving a PDE with the Galerkin method and method of lines consists of three steps. </i> </div> </div> <h4 id="method-of-lines">Method of Lines</h4> <p>If we can evaluate the right hand side \(m\), then the equations are easily solvable with time derivatives. In particular, we can consider a <em>stacked</em> version of multiple scalar fields instead of vector ones as</p> \[\begin{equation} A \partial_t C = M \end{equation} \tag{1}\] <p>where \(M\) are \(m\)-dimensional matrices due to \(m\)-scalar fields. In practice, we have transformed a PDE into a matrix ODE (ordinary differential equation) by discretizing in space; we managed to obtain a much simpler way of solving our problem by only needing to <em>integrate</em> over time: a much simpler task!</p> <h2 id="2-motivation"><strong>2. Motivation</strong></h2> <p>PDEs are the <em>language of nature</em> and as such they are incredibly important for the scientific community. However, many hand-crafted models either take too long to compute solutions or do not have enough expressibility. Therefore, it is necessary to include at least partial, <em>data-driven</em> terms that can learn from past experiences.</p> <p>Machine and Deep Learning have proven incredibly powerful tools for solving real-world complex phenomena: they can accelerate simulations by orders of magnitude enabling faster predictions, design and control and even describe previously unknown dynamics which cannot be derived by equations.</p> <p>There are mainly two lines of research in the area of PDEs and Deep Learning: either constraining PDE solution learning with a cost function, or learning directly from data to obtain a simulator via inductive biases.</p> <p>In this work, the authors follow the second path and derive a model which sprouts from research on numerical methods for differential equations and can incorporate knowledge of dynamics (such as transport terms).</p> <h2 id="3-method-finite-element-networks"><strong>3. Method: Finite Element Networks</strong></h2> <h4 id="from-the-finite-element-equation-to-learnable-models">From the Finite Element Equation to Learnable Models</h4> <p>We would like to find solutions to a PDE process via a data-driven simulator. Given the Finite Element <a href="#method-of-lines">Equation 1</a>, we can rewrite its terms as following:</p> <p>\(A \partial_t Y^{(t)} = M\) where \(A\) is the mass matrix and \(Y\) is the feature matrix - in other words, this part represents the <em>feature update</em> in time that we need to obtain the dynamics evolution in time. The problem at inference time then becomes:</p> <ol> <li>Evaluate matrix \(A\) and inverting it</li> <li>Evaluating matrix \(M\)</li> </ol> <p>We can readily obtain \(A\) by <em>mass lumping</em> [2] which allows for a good performance of the matrix inversion necessary to obtain \(\partial_t Y^{(t)}\). The right-hand term describing the <em>dynamics</em> as we have seen before requires an evaluation of the contribution of dynamics of adjacent cells:</p> \[M_{ik} = \langle F(t, x, u, \dots)_k, \varphi^{(i)} \rangle_\Omega = \sum_{\Delta} \langle F(t, x, u, \dots)_k, \varphi^{(i)} \rangle_{CH(\Delta)}\] <p>where $\Delta$ is the set of mesh cells adjacent to \(x^{(i)}\) and \(CH(\Delta)\) is the <em>convex hull</em> (i.e., smallest convex set of $\Delta$ that contains it). As we can see, evaluating $M$ (which we call the <strong>message matrix</strong>) is actually the same as operating <strong>message passing</strong> between adjacent cells. This means that we can represent these dynamics with a Message Passing Neural Network!</p> <div style="width:80%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/FEN-catchy-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/FEN-catchy-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/FEN-catchy-1400.webp"></source> <img src="/assets/img/blogs/fen/FEN-catchy.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure .<i> Finite Element Networks: we can evaluate dynamics by message passing over adjacent cells and integrating this value to obtain the future values. </i> </div> </div> <p>Moreover, by factoring the inner product on the right side of the previous equation as</p> \[\langle F(t, x, u, \dots)_k, \varphi^{(i)} \rangle_{CH(\Delta)} = F_{\Delta, k}^{(i)} \cdot \langle 1, \varphi^{(i)} \rangle_{CH(\Delta)} \tag{2}\] <p>we can avoid numerical instabilities and learn spatial derivatives as well. This means that we can learn a model \(f_\theta \approx F_\Delta^{(i)}\)!</p> <h4 id="model">Model</h4> <p>We have seen from <a href="#from-the-finite-element-equation-to-learnable-models">Equation 2</a> that we can learn a model by performing message passing over adjacent cells. In particular, the learned model \(f_\theta\) can be written as:</p> \[f_{\theta, \Delta}^{(t, i)} = f_\theta \left( t, \mu_\Delta, x_\Delta, y_\Delta^{(t)} \right)^{(i)} \approx F_\Delta^{(i)}\] <p>where \(\mu_\Delta\) is the center of cell \(\Delta\), \(x_\Delta\) are the coordinates of cell vertices w.r.t. \(\mu\) and \(y^{(t)}\) are the features at the vertices at time \(t\). We have written the equations for a single message passing step, which is the update at each single time step. To obtain a whole trajectory, we need to solve the associated ODE given an initial condition \(y^{(t_0)}\) and times \(t \in 0, 1, \dots, T\):</p> \[y^{(t_0, t_1, \dots, t_N)} = \text{ODESolve}(y^{(t_0)}, \partial_t y , t)\] <p>This ODE can be solved in a variety of ways. In particular, the authors employ the \(\tt dopri5\) adaptive-step solver, i.e., an solver that iterative computes the solution by calling the function multiple times. We resulting model <strong>FEN</strong>: Finite Element Network.</p> <h4 id="modeling-the-transport-term">Modeling the Transport Term</h4> <p>What if we have some extra knowledge about the domain? For example, an assumption on the dynamics \(F\) could be that our solution would be at least in part governed by a <em>convective component</em> (i.e. describing fluid motion):</p> \[F(t, x, u, \dots)_k= \underbrace{ - \nabla \cdot (v^{(k)} (t, x, u, \dots) u_k)}_{convection~term} + \underbrace{F'(t, x, u, \dots)_k}_{remainder~dynamics}\] <p>where \(v\) is the divergence-free velocity term.</p> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/airfoils-example-velocity-field-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/airfoils-example-velocity-field-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/airfoils-example-velocity-field-1400.webp"></source> <img src="/assets/img/blogs/fen/airfoils-example-velocity-field.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> Example flow field around airfoils present convective components.</i> </div> </div> <p>We can model \(F'\) as in the previous case while we can model the convection term by message passing with the following network \(g_\vartheta\):</p> \[f^v_{msg} (\Delta)_{x^{(i)}} = \sum_{x^{(j)} \in \Delta} y^{(t, j)} \odot \left( g_{\vartheta,\Delta}^{(t, i)} \cdot \langle \nabla \varphi^{(j)}, \varphi^{(i)} \rangle_{CH(\Delta)} \right)\] <p>The final model, which is called <strong>T-FEN</strong>: Trasport-FEN, is the sum of the message passing of the above convection term and \(F'\) and is thus designed to capture both a velocity field and remainder dynamics.</p> <h2 id="4-experiments"><strong>4. Experiments</strong></h2> <h3 id="baselines">Baselines</h3> <p>The authors consider the following baselines:</p> <ul> <li> <strong>Graph WaveNet (GWN)</strong>: combines temporal and graph convolutions [3]</li> <li> <strong>Physics-aware Difference Graph Network (PA-DGN)</strong>: estimates spatial derivatives as additional features for a recurrent graph network [4]</li> <li> <strong>Continuous-time MPNN (CT-MPNN)</strong> model in uses a general MPNN to learn the continuous-time dynamics of the data [5]</li> </ul> <h3 id="datasets">Datasets</h3> <h4 id="cylinder-flow">Cylinder Flow</h4> <p>The following dataset consists of simulated flow fields around a cylinder as collected by [6]. The dataset includes velocities and pressures along with marked mesh cells representing boundary walls, inlets, outlets and cylindrical obstacles of varying sizes. The sequences contain \(600\) frames and are divided in \(1000-100-100\) for train, validation and test. The time resolution \(\Delta t\) is of \(0.01~s\).</p> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/cylinder-flow-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/cylinder-flow-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/cylinder-flow-1400.webp"></source> <img src="/assets/img/blogs/fen/cylinder-flow.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> Example flow field around airfoils present convective components.</i> </div> </div> <h4 id="black-sea">Black Sea</h4> <p>This dataset is composed data on daily mean sea surface temperature and water velocities on the Black Sea over several years. The training data is made of frames from 2012 to 2017, validation is on frames from 2018 and testing is done with frames from the year 2019. The time resolution \(\Delta t\) is of 1 day.</p> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/black-sea-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/black-sea-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/black-sea-1400.webp"></source> <img src="/assets/img/blogs/fen/black-sea.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> Learned flow fields of water velocities on the Black Sea dataset: T-FEN recognized the relationships between features. </i> </div> </div> <h4 id="scalarflow">ScalarFlow</h4> <p>This dataset consists of 3D reconstructions generated by multiple camera views of rising hot smoke plumes in a real environment. The sequences contain \(150\) frames and are divided in \(64-20-20\) for train, validation and test. The time resolution \(\Delta t\) is of \(0.0167~s\) (recording was done at 60 fps)[7].</p> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/scalarflow-comparison-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/scalarflow-comparison-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/scalarflow-comparison-1400.webp"></source> <img src="/assets/img/blogs/fen/scalarflow-comparison.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> Long-range extrapolations on the ScalarFlow dataset (60 time steps). FEN models perform better than the strongest baseline by also better modeling of sources and sinks. </i> </div> </div> <h3 id="model-parameters">Model Parameters</h3> <p>Both networks \(f_\theta\) and \(g_\vartheta\) are <em>multi-layer perceptrons</em> (MLPs) with $\tt tanh$ nonlinearities. The number of parameters of each network was kept similar between FEN and T-FEN models and lower than baseline to demonstrate their capabilities.</p> <h3 id="results">Results</h3> <h4 id="multi-step-forecasting">Multi-step Forecasting</h4> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/table-experiments-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/table-experiments-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/table-experiments-1400.webp"></source> <img src="/assets/img/blogs/fen/table-experiments.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> Multi-step Forecasting. </i> </div> </div> <p>This experiments aims at predicting \(10\) steps in the future. We can see that FEN models either outperform or achieve similar, competitive results with the baselines.</p> <h4 id="super-resolution">Super-resolution</h4> <div style="width:60%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/plot-mae-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/plot-mae-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/plot-mae-1400.webp"></source> <img src="/assets/img/blogs/fen/plot-mae.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> Errors with super-resolution in the number of nodes. </i> </div> </div> <p>This experiments aims at predicting \(10\) steps in the future as before but with varying number of nodes, i.e. more nodes than those seen during training. FEN models outperform baselines in super-resolution: T-FEN models always perform better than FEN counterparts since they can better represent transport terms.</p> <h4 id="extrapolation">Extrapolation</h4> <div style="width:100%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/scalarflow-extrapolation-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/scalarflow-extrapolation-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/scalarflow-extrapolation-1400.webp"></source> <img src="/assets/img/blogs/fen/scalarflow-extrapolation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> Extrapolation over 60 steps. </i> </div> </div> <p>This experiments aims at predicting \(60\) steps in the future with models trained on \(10\) steps. FEN models outperform baselines since they can correctly represent sources and sinks.</p> <h4 id="interpretability">Interpretability</h4> <div style="width:50%; margin:0 auto; text-align: center;"> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/blogs/fen/freeform-transport-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/blogs/fen/freeform-transport-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/blogs/fen/freeform-transport-1400.webp"></source> <img src="/assets/img/blogs/fen/freeform-transport.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <i> T-FEN model providing an interpretable splitting between free-form and transport term. </i> </div> </div> <p>This experiments aims at providing interpretability and a justification for the T-FEN model. Plotting the free-form and transport term separately provides an interesting view into the learning process which is interpretable - the transport represents the differences in flow field.</p> <h2 id="5-conclusion"><strong>5. Conclusion</strong></h2> <p>We have reviewed <em>Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks</em>, a novel graph paradigm for learning dynamics on graphs based on inductive biases from differential equations. The authors provided a detailed analysis of the method from the ground up - starting from the theory of Finite Element analysis - and then devised two main models variations. While the first one learns directly the solution derivative in time of the physical system, the second separates learning with a <em>transport term</em> which is shown to improve learning under many conditions. The experiments were conducted in one syntethic and two real-world high-dimensional datasets. Results demonstrated that the proposed models either perform competitively or outperform state-of-the-art baselines. This work represents and important contribution to the scientific machine learning community by tightly integrating the theory of Finite Element Method and Graph Neural Networks.</p> <h4 id="limitations">Limitations</h4> <p>The proposed model uses a simple basis - namely, linear piecewise basis function. If higher order derivatives were used, such as second order, these basis functions would evaluate to \(0\), which is thus a current limitation of the model. Another limitation is the number of function evaluations: it is shown that the models can take more than 300 evaluations, while other non-continuous models may require just one. This is due to the adaptive ODE solvers used. Although the model can theoretically describe continuous dynamics, this practically makes it way slower than <em>one-step-prediction</em> counterparts that do not need to evaluate an ODE.</p> <hr> <h2 id="author-information"><strong>Author Information</strong></h2> <p><strong>Federico Berto</strong> <a href="https://fedebotu.github.io/" target="_blank" rel="noopener noreferrer">Personal Website</a></p> <p>Affiliation: KAIST, Industrial &amp; Systems Engineering Department</p> <p>MSc students at <a href="http://silab.kaist.ac.kr/" target="_blank" rel="noopener noreferrer">SILAB</a></p> <p>Member of the open research group <a href="https://github.com/DiffEqML" target="_blank" rel="noopener noreferrer">DiffEqML</a></p> <h2 id="6-reference--additional-materials"><strong>6. Reference &amp; Additional materials</strong></h2> <h3 id="github-implementation">Github Implementation</h3> <p><a href="https://github.com/martenlienen/finite-element-networks" target="_blank" rel="noopener noreferrer">https://github.com/martenlienen/finite-element-networks</a>.</p> <h3 id="references">References</h3> <p>[1] Lienen, Marten, and Stephan Günnemann. “Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks.” ICLR (2022).</p> <p>[2] Lapidus, Leon, and George F. Pinder. “Numerical solution of partial differential equations in science and engineering”. John Wiley &amp; Sons (2011).</p> <p>[3] Wu, Zonghan, et al. “Graph wavenet for deep spatial-temporal graph modeling.” CoRR (2019).</p> <p>[4] Seo, Sungyong, Chuizheng Meng, and Yan Liu. “Physics-aware difference graph networks for sparsely-observed dynamics.” ICLR (2019).</p> <p>[5] Iakovlev, Valerii, Markus Heinonen, and Harri Lähdesmäki. “Learning continuous-time PDEs from sparse data with graph neural networks.” ICLR (2021).</p> <p>[6] Pfaff, Tobias, et al. “Learning mesh-based simulation with graph networks. ICLR (2021).</p> <p>[7] Eckert, Marie-Lena, Kiwon Um, and Nils Thuerey. “ScalarFlow: a large-scale volumetric data set of real-world scalar transport flows for computer animation and machine learning.” ACM Transactions on Graphics (TOG) (2019)</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2022 Minsu Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. Last updated: October 09, 2022. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>